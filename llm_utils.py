"""
llm_utils.py
------------
Utilities for combining files using an LLM (OpenAI API) for the Confluence Downloader project.
"""
import openai
import os
from tqdm import tqdm
import time
from itertools import cycle

def combine_files_with_llm(file_paths, output_dir, api_key, model="gpt-4", output_filename="LLM_Combined.md", overwrite_mode="overwrite"):
    """
    Combine the given files using an LLM and save the result as a Markdown file.

    Args:
        file_paths (list): List of file paths to combine.
        output_dir (str): Directory to save the combined file.
        api_key (str): OpenAI API key.
        model (str): OpenAI model to use (default: gpt-4).
        output_filename (str): Name of the output Markdown file.
        overwrite_mode (str): 'overwrite' (default) or 'increment' to avoid overwriting existing files.
    Returns:
        str: Path to the combined Markdown file, or None on error.
    """
    # The prompt instructs the LLM to combine, deduplicate, and improve the content
    prompt = (
        "You are acting as a professional technical writer. Your goal is to create a single, comprehensive, and easy-to-navigate Markdown document that combines the content of all these files. "
        "The final document should be accurate, logically organized, visually clear, and suitable for onboarding, reference, and knowledge transfer for both new and experienced users.\n"
        "Combine the content of all these files into a well-structured Markdown document.\n"
        "At the very top of the document, add a short note explaining that all content marked with a ðŸ¤– emoji or special formatting was generated by an AI assistant and is not present in the original files.\n"
        "Immediately after, add a 'Formatting Guide' section that describes:\n"
        "  - How LLM-supplied content is marked (ðŸ¤– for paragraphs, inline code or italics for small contributions).\n"
        "  - That original content is unmarked.\n"
        "  - That the document uses Markdown formatting (headings, lists, tables, blockquotes, etc.) for clarity and navigation, and readers are encouraged to take advantage of these features.\n"
        "- Ensure that all unique information from each file is preserved and not lost.\n"
        "- Remove any duplicate or redundant content.\n"
        "- Organize the document into clear, logical sections with appropriate headings and subheadings.\n"
        "- If the document is long, create a table of contents at the top.\n"
        "- Group related information together, and reorder content as needed to improve logical flow and coherence.\n"
        "- Where possible, cross-reference related sections and synthesize information from multiple sources to provide a unified explanation.\n"
        "- Resolve any inconsistencies between files, and note any ambiguities or gaps in the source material.\n"
        "- Enhance readability by rewriting awkward or unclear passages, correcting grammar, and improving transitions between sections.\n"
        "- Where helpful, add actionable summaries, best practices, or checklists for users.\n"
        "- Use bullet points, tables, and diagrams (in Markdown) to clarify complex information.\n"
        "- Where possible, add summaries or introductions to major sections for clarity.\n"
        "- Where helpful, add additional context such as: summaries of tools, version numbers, summaries of broad topics, and lists of important keywords.\n"
        "- Call out important warnings, tips, or caveats using blockquotes or bold formatting.\n"
        "- Mark all supplemental context you provide (not found in the original files):\n"
        "    - For descriptions or paragraphs, prefix with a robot emoji ðŸ¤–.\n"
        "    - For smaller contributions (e.g., a single word, keyword, or short phrase), use small color formatting such as inline code or italics.\n"
        "- Do not omit any important technical or contextual details from the original files.\n"
        "- The final document should be easy to navigate, comprehensive, and professional in quality."
    )
    print("\n[LLM] Preparing to read files for combination...")
    combined_content = ""
    # Read and concatenate all file contents, separating with headers
    for file_path in tqdm(file_paths, desc="Reading files for LLM combine"):
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                file_content = f.read()
            combined_content += f"\n\n---\n\n# {os.path.basename(file_path)}\n\n" + file_content
        except Exception as e:
            print(f"Error reading {file_path}: {e}")
    print("[LLM] Finished reading and preparing files.")
    # Set the OpenAI API key
    openai.api_key = api_key
    try:
        print("[LLM] Sending content to OpenAI for combination. This may take a few moments...")
        # Show a spinner while waiting for the API call
        import threading
        stop_spinner = False
        def spinner():
            for c in cycle(['|', '/', '-', '\\']):
                if stop_spinner:
                    break
                print(f'\r[LLM] Waiting for OpenAI response... {c}', end='', flush=True)
                time.sleep(0.1)
            print('\r', end='', flush=True)
        spinner_thread = threading.Thread(target=spinner)
        spinner_thread.start()
        # Call the OpenAI chat completion API
        response = openai.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "You are a helpful technical writer."},
                {"role": "user", "content": prompt + "\n\n" + combined_content}
            ],
            max_tokens=4096  # adjust as needed
        )
        stop_spinner = True
        spinner_thread.join()
        print("[LLM] Received response from OpenAI.")
        llm_output = response.choices[0].message.content
    except Exception as e:
        print(f"Error calling OpenAI API: {e}")
        return None
    # Write the LLM's output to the specified Markdown file
    output_path = os.path.join(output_dir, output_filename)
    if overwrite_mode == "increment":
        name, ext = os.path.splitext(output_filename)
        i = 2
        while os.path.exists(output_path):
            new_filename = f"{name}_{i}{ext}"
            output_path = os.path.join(output_dir, new_filename)
            i += 1
    try:
        print(f"[LLM] Writing combined content to {output_path} ...")
        for _ in tqdm(range(20), desc="Writing file", ncols=70):
            time.sleep(0.01)  # Simulate progress for user feedback
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(llm_output)
        print(f"[LLM] Successfully wrote combined file: {output_path}")
    except Exception as e:
        print(f"Error writing LLM-combined file: {e}")
        return None
    return output_path 